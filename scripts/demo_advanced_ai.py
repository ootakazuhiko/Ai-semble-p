#!/usr/bin/env python3
"""
é«˜åº¦ãªAIãƒ¢ãƒ‡ãƒ«çµ±åˆæ©Ÿèƒ½ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
Ai-semble v2ã®è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸æŠã¨å‹•çš„ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®å®Ÿæ¼”
"""
import asyncio
import aiohttp
import json
import time
from typing import Dict, Any, List
import argparse
from datetime import datetime

class AdvancedAIDemoClient:
    """é«˜åº¦ãªAIçµ±åˆæ©Ÿèƒ½ã®ãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self, base_url: str = "http://localhost:8080"):
        self.base_url = base_url
        self.session = None
    
    async def __aenter__(self):
        """éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼é–‹å§‹"""
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼çµ‚äº†"""
        if self.session:
            await self.session.close()
    
    async def demo_auto_model_selection(self):
        """è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸æŠã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print("ğŸ¤– è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        print("=" * 50)
        
        # æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã§ã®è‡ªå‹•é¸æŠã‚’ãƒ†ã‚¹ãƒˆ
        test_cases = [
            {
                "name": "ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¿ã‚¹ã‚¯",
                "prompt": "def fibonacci(n): # Complete this Python function to calculate fibonacci numbers",
                "priority": "quality"
            },
            {
                "name": "æ—¥æœ¬èªå‰µä½œã‚¿ã‚¹ã‚¯", 
                "prompt": "æ¡œãŒå’²ãæ˜¥ã®æ—¥ã«ã€å°ã•ãªæ‘ã§èµ·ã“ã£ãŸå¿ƒæ¸©ã¾ã‚‹ç‰©èªã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚",
                "priority": "balanced"
            },
            {
                "name": "åŒ»ç™‚ç›¸è«‡ã‚¿ã‚¹ã‚¯",
                "prompt": "What are the common symptoms of diabetes and how can it be managed?",
                "priority": "quality"
            },
            {
                "name": "æ•°å­¦å•é¡Œã‚¿ã‚¹ã‚¯",
                "prompt": "Solve this equation: 2x + 5 = 15. Show your work step by step.",
                "priority": "balanced"
            },
            {
                "name": "æ³•å¾‹ç›¸è«‡ã‚¿ã‚¹ã‚¯",
                "prompt": "What are the key elements of a valid contract under common law?",
                "priority": "quality"
            },
            {
                "name": "ã‚³ã‚¹ãƒˆé‡è¦–ã‚¿ã‚¹ã‚¯",
                "prompt": "Write a brief summary of renewable energy benefits.",
                "priority": "cost"
            }
        ]
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ“‹ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}: {test_case['name']}")
            print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {test_case['prompt'][:50]}...")
            print(f"å„ªå…ˆåº¦: {test_case['priority']}")
            
            # ãƒ¢ãƒ‡ãƒ«é¸æŠAPIå‘¼ã³å‡ºã—
            selection_result = await self._call_model_selection(
                test_case['prompt'],
                priority=test_case['priority']
            )
            
            if selection_result:
                print(f"âœ… é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: {selection_result['selected_model']}")
                print(f"   ä¿¡é ¼åº¦: {selection_result['confidence']:.2f}")
                print(f"   ç†ç”±: {selection_result['reason']}")
                if selection_result.get('fallback_models'):
                    print(f"   ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {', '.join(selection_result['fallback_models'])}")
            else:
                print("âŒ ãƒ¢ãƒ‡ãƒ«é¸æŠã«å¤±æ•—")
            
            await asyncio.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®
    
    async def demo_dynamic_model_management(self):
        """å‹•çš„ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print("\nğŸ”§ å‹•çš„ãƒ¢ãƒ‡ãƒ«ç®¡ç†ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        print("=" * 50)
        
        # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
        print("\nğŸ“Š ç¾åœ¨ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«:")
        models = await self._get_models()
        if models:
            for category, category_models in models.get('models', {}).items():
                if isinstance(category_models, dict):
                    print(f"  {category}: {len(category_models)} models")
                    for model_name in list(category_models.keys())[:3]:  # æœ€åˆã®3ã¤ã ã‘è¡¨ç¤º
                        print(f"    - {model_name}")
                    if len(category_models) > 3:
                        print(f"    ... and {len(category_models) - 3} more")
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²
        print("\nâ• ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®ç™»éŒ²:")
        custom_model = {
            "category": "llm_models",
            "model_name": "demo-custom-model",
            "model_info": {
                "provider": "demo",
                "task": "llm",
                "capabilities": ["demo_task", "test_generation"],
                "quality_score": 0.85,
                "speed_score": 0.90,
                "cost_per_token": 0.001,
                "local": True
            }
        }
        
        register_result = await self._register_model(custom_model)
        if register_result:
            print(f"âœ… ãƒ¢ãƒ‡ãƒ« '{custom_model['model_name']}' ã‚’æ­£å¸¸ã«ç™»éŒ²")
        else:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ç™»éŒ²ã«å¤±æ•—")
        
        # ç™»éŒ²ã—ãŸãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’å–å¾—
        print(f"\nğŸ“– ç™»éŒ²ã—ãŸãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±:")
        model_info = await self._get_model_info(custom_model['model_name'])
        if model_info:
            print(json.dumps(model_info, indent=2, ensure_ascii=False))
        
        # ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆã‚’è¡¨ç¤º
        print(f"\nğŸ“ˆ ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆ:")
        stats = await self._get_model_stats()
        if stats:
            print(f"  ç·ãƒ¢ãƒ‡ãƒ«æ•°: {stats.get('total_models', 0)}")
            print(f"  ã‚«ãƒ†ã‚´ãƒªåˆ¥:")
            for category, count in stats.get('categories', {}).items():
                print(f"    {category}: {count}")
            print(f"  ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥:")
            for provider, count in stats.get('providers', {}).items():
                print(f"    {provider}: {count}")
        
        # ç™»éŒ²ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ï¼ˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼‰
        print(f"\nğŸ—‘ï¸  ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—:")
        delete_result = await self._delete_model(custom_model['model_name'])
        if delete_result:
            print(f"âœ… ãƒ¢ãƒ‡ãƒ« '{custom_model['model_name']}' ã‚’å‰Šé™¤")
        else:
            print("âŒ ãƒ¢ãƒ‡ãƒ«å‰Šé™¤ã«å¤±æ•—")
    
    async def demo_smart_llm_completion(self):
        """ã‚¹ãƒãƒ¼ãƒˆLLMè£œå®Œã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print("\nğŸ§  ã‚¹ãƒãƒ¼ãƒˆLLMè£œå®Œãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        print("=" * 50)
        
        # ç•°ãªã‚‹å„ªå…ˆåº¦ã§ã®åŒã˜ã‚¿ã‚¹ã‚¯ã®ãƒ†ã‚¹ãƒˆ
        test_prompt = "Explain the concept of machine learning in simple terms."
        priorities = ["quality", "cost", "balanced"]
        
        for priority in priorities:
            print(f"\nğŸ¯ å„ªå…ˆåº¦: {priority}")
            
            request_data = {
                "prompt": test_prompt,
                "model": "auto",  # è‡ªå‹•é¸æŠ
                "max_tokens": 150,
                "temperature": 0.7,
                "priority": priority,
                "auto_select": True
            }
            
            start_time = time.time()
            result = await self._call_llm_completion(request_data)
            end_time = time.time()
            
            if result:
                print(f"âœ… å‡¦ç†å®Œäº†:")
                print(f"   ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {result.get('model_used', 'N/A')}")
                print(f"   é¸æŠç†ç”±: {result.get('selection_reason', 'N/A')}")
                print(f"   å‡¦ç†æ™‚é–“: {result.get('processing_time', 0):.2f}ç§’")
                print(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {end_time - start_time:.2f}ç§’")
                print(f"   çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {result.get('result', '')[:100]}...")
            else:
                print("âŒ LLMè£œå®Œã«å¤±æ•—")
            
            await asyncio.sleep(1)  # æ¬¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§å¾…æ©Ÿ
    
    async def demo_capability_based_search(self):
        """èƒ½åŠ›ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print("\nğŸ” èƒ½åŠ›ãƒ™ãƒ¼ã‚¹æ¤œç´¢ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        print("=" * 50)
        
        capabilities_to_test = [
            "text_generation",
            "code_generation", 
            "image_segmentation",
            "sentiment_analysis",
            "translation"
        ]
        
        for capability in capabilities_to_test:
            print(f"\nğŸ¯ èƒ½åŠ›: {capability}")
            
            models = await self._get_models_by_capability(capability)
            if models and models.get('models'):
                print(f"âœ… {len(models['models'])} models found:")
                for model in models['models'][:5]:  # æœ€åˆã®5ã¤ã¾ã§è¡¨ç¤º
                    print(f"   - {model}")
                if len(models['models']) > 5:
                    print(f"   ... and {len(models['models']) - 5} more")
            else:
                print(f"âŒ èƒ½åŠ› '{capability}' ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    async def demo_comprehensive_workflow(self):
        """åŒ…æ‹¬çš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print("\nğŸš€ åŒ…æ‹¬çš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        print("=" * 50)
        
        # 1. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        print("\n1ï¸âƒ£ ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯")
        health_result = await self._check_health()
        if health_result:
            print("âœ… ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œä¸­")
        else:
            print("âŒ ã‚·ã‚¹ãƒ†ãƒ ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
            return
        
        # 2. ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆã®è¡¨ç¤º
        print("\n2ï¸âƒ£ ã‚·ã‚¹ãƒ†ãƒ ã®ç¾åœ¨çŠ¶æ…‹")
        stats = await self._get_model_stats()
        if stats:
            print(f"ç™»éŒ²æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: {stats.get('total_models', 0)}")
        
        # 3. ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã§ã®è‡ªå‹•é¸æŠãƒ†ã‚¹ãƒˆ
        print("\n3ï¸âƒ£ ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯è‡ªå‹•é¸æŠãƒ†ã‚¹ãƒˆ")
        tasks = [
            "Write a Python function to reverse a string",
            "æ—¥æœ¬èªã§ä¿³å¥ã‚’ä½œã£ã¦ãã ã•ã„", 
            "Explain quantum computing basics"
        ]
        
        for i, task in enumerate(tasks, 1):
            print(f"\nã‚¿ã‚¹ã‚¯ {i}: {task}")
            selection = await self._call_model_selection(task)
            if selection:
                print(f"  â†’ é¸æŠ: {selection['selected_model']} (ä¿¡é ¼åº¦: {selection['confidence']:.2f})")
        
        # 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
        print("\n4ï¸âƒ£ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š")
        request_data = {
            "prompt": "Quick test prompt for performance measurement",
            "model": "auto",
            "max_tokens": 50
        }
        
        times = []
        for i in range(3):
            start = time.time()
            result = await self._call_llm_completion(request_data)
            end = time.time()
            if result:
                times.append(end - start)
        
        if times:
            avg_time = sum(times) / len(times)
            print(f"  å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {avg_time:.2f}ç§’")
            print(f"  æœ€å°æ™‚é–“: {min(times):.2f}ç§’")
            print(f"  æœ€å¤§æ™‚é–“: {max(times):.2f}ç§’")
    
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    async def _call_model_selection(self, prompt: str, priority: str = "balanced") -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«é¸æŠAPIã‚’å‘¼ã³å‡ºã—"""
        try:
            async with self.session.post(
                f"{self.base_url}/models/select",
                json={
                    "prompt": prompt,
                    "task_type": "llm",
                    "priority": priority,
                    "max_tokens": 100
                }
            ) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    print(f"Model selection failed: {response.status}")
                    return None
        except Exception as e:
            print(f"Error calling model selection: {e}")
            return None
    
    async def _get_models(self) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        try:
            async with self.session.get(f"{self.base_url}/models/") as response:
                if response.status == 200:
                    return await response.json()
                return None
        except Exception as e:
            print(f"Error getting models: {e}")
            return None
    
    async def _register_model(self, model_data: Dict[str, Any]) -> bool:
        """ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²"""
        try:
            async with self.session.post(
                f"{self.base_url}/models/register",
                json=model_data
            ) as response:
                return response.status == 200
        except Exception as e:
            print(f"Error registering model: {e}")
            return False
    
    async def _get_model_info(self, model_name: str) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
        try:
            async with self.session.get(f"{self.base_url}/models/{model_name}") as response:
                if response.status == 200:
                    return await response.json()
                return None
        except Exception as e:
            print(f"Error getting model info: {e}")
            return None
    
    async def _get_model_stats(self) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆã‚’å–å¾—"""
        try:
            async with self.session.get(f"{self.base_url}/models/stats") as response:
                if response.status == 200:
                    return await response.json()
                return None
        except Exception as e:
            print(f"Error getting model stats: {e}")
            return None
    
    async def _delete_model(self, model_name: str) -> bool:
        """ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤"""
        try:
            async with self.session.delete(f"{self.base_url}/models/{model_name}") as response:
                return response.status == 200
        except Exception as e:
            print(f"Error deleting model: {e}")
            return False
    
    async def _call_llm_completion(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """LLMè£œå®ŒAPIã‚’å‘¼ã³å‡ºã—"""
        try:
            async with self.session.post(
                f"{self.base_url}/ai/llm/completion",
                json=request_data
            ) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    print(f"LLM completion failed: {response.status}")
                    return None
        except Exception as e:
            print(f"Error calling LLM completion: {e}")
            return None
    
    async def _get_models_by_capability(self, capability: str) -> Dict[str, Any]:
        """èƒ½åŠ›åˆ¥ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        try:
            async with self.session.get(
                f"{self.base_url}/models/capabilities/{capability}"
            ) as response:
                if response.status == 200:
                    return await response.json()
                return None
        except Exception as e:
            print(f"Error getting models by capability: {e}")
            return None
    
    async def _check_health(self) -> bool:
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        try:
            async with self.session.get(f"{self.base_url}/health") as response:
                return response.status == 200
        except Exception as e:
            print(f"Error checking health: {e}")
            return False


async def main():
    parser = argparse.ArgumentParser(description="Ai-semble v2 Advanced AI Integration Demo")
    parser.add_argument("--url", default="http://localhost:8080", 
                       help="Base URL of Ai-semble v2 orchestrator")
    parser.add_argument("--demo", choices=["auto", "management", "completion", "search", "all"], 
                       default="all", help="Demo type to run")
    
    args = parser.parse_args()
    
    print("ğŸ­ Ai-semble v2 é«˜åº¦ãªAIçµ±åˆæ©Ÿèƒ½ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 60)
    print(f"æ¥ç¶šå…ˆ: {args.url}")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now().isoformat()}")
    print()
    
    async with AdvancedAIDemoClient(args.url) as demo:
        try:
            if args.demo in ["auto", "all"]:
                await demo.demo_auto_model_selection()
            
            if args.demo in ["management", "all"]:
                await demo.demo_dynamic_model_management()
            
            if args.demo in ["completion", "all"]:
                await demo.demo_smart_llm_completion()
            
            if args.demo in ["search", "all"]:
                await demo.demo_capability_based_search()
            
            if args.demo == "all":
                await demo.demo_comprehensive_workflow()
            
            print("\nâœ… ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†!")
            print("=" * 60)
            
        except KeyboardInterrupt:
            print("\nâš ï¸  ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


if __name__ == "__main__":
    asyncio.run(main())