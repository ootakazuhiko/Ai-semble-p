# Ai-semble v2 æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¬ã‚¤ãƒ‰

## ğŸ¯ æ¦‚è¦

ã“ã®ã‚¬ã‚¤ãƒ‰ã¯ã€Ai-semble v2ã‚’Podmanç’°å¢ƒã§æœ¬ç•ªé‹ç”¨ã™ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªæ‰‹é †ã‚’æä¾›ã—ã¾ã™ã€‚

## ğŸ“‹ å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯

### ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶

```bash
# OSè¦ä»¶ç¢ºèª
cat /etc/os-release

# æ¨å¥¨OS:
# - Red Hat Enterprise Linux 8/9
# - CentOS Stream 8/9  
# - Fedora 36+
# - Ubuntu 22.04+
```

### å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª

```bash
# Podman 4.0+
podman --version

# systemd
systemctl --version

# crun (GPUä½¿ç”¨æ™‚)
crun --version

# å¿…è¦ãªãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ (æœ€å°50GBæ¨å¥¨)
df -h

# ãƒ¡ãƒ¢ãƒª (æœ€å°16GBæ¨å¥¨)
free -h

# CPU (æœ€å°4ã‚³ã‚¢æ¨å¥¨)
nproc
```

## ğŸ”§ ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š

```bash
# å°‚ç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ
sudo useradd -m -s /bin/bash ai-semble
sudo usermod -aG wheel ai-semble  # RHEL/CentOS
# sudo usermod -aG sudo ai-semble  # Ubuntu

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ‡ã‚Šæ›¿ãˆ
sudo su - ai-semble

# Rootlessè¨­å®š
loginctl enable-linger ai-semble

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åå‰ç©ºé–“è¨­å®š (ç®¡ç†è€…æ¨©é™ã§å®Ÿè¡Œ)
echo "ai-semble:100000:65536" | sudo tee -a /etc/subuid
echo "ai-semble:100000:65536" | sudo tee -a /etc/subgid
```

### 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š

```bash
# SELinuxè¨­å®š (ç®¡ç†è€…æ¨©é™)
sudo ./scripts/install-security.sh

# ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®šç¢ºèª
sudo firewall-cmd --list-ports
# 8080-8084/tcp ãŒé–‹æ”¾ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
```

### 3. GPUè¨­å®š (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

```bash
# NVIDIA Container Toolkitè¨­å®š
sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml

# GPUèªè­˜ç¢ºèª
podman run --rm --device nvidia.com/gpu=all nvidia/cuda:11.8-base-ubuntu22.04 nvidia-smi
```

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹é †

### Phase 1: åŸºæœ¬ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/ootakazuhiko/Ai-semble-p.git
cd Ai-semble-p

# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Ÿè¡Œ
./scripts/setup.sh 2>&1 | tee setup.log

# å®Ÿè¡Œçµæœç¢ºèª
tail -20 setup.log
```

### Phase 2: å‹•ä½œç¢ºèª

```bash
# Podèµ·å‹•
./scripts/deploy.sh start

# çŠ¶æ…‹ç¢ºèª
./scripts/deploy.sh status

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
./scripts/deploy.sh health
```

### Phase 3: çµ±åˆãƒ†ã‚¹ãƒˆ

```bash
# åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
./scripts/run-tests.sh quick

# çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
./scripts/run-tests.sh integration
```

## ğŸ“Š å‹•ä½œç¢ºèªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### å¿…é ˆãƒã‚§ãƒƒã‚¯é …ç›®

- [ ] **Podèµ·å‹•ç¢ºèª**
  ```bash
  podman pod ps | grep ai-semble
  # ai-semble   Running   5 containers
  ```

- [ ] **å…¨ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ç¢ºèª**
  ```bash
  podman ps --pod | grep ai-semble
  # 5ã¤ã®ã‚³ãƒ³ãƒ†ãƒŠãŒå…¨ã¦RunningçŠ¶æ…‹
  ```

- [ ] **ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯**
  ```bash
  curl http://localhost:8080/health
  # {"status":"healthy",...}
  ```

- [ ] **å„ã‚µãƒ¼ãƒ“ã‚¹å€‹åˆ¥ç¢ºèª**
  ```bash
  # Orchestrator
  curl http://localhost:8080/health
  
  # LLM Service
  curl http://localhost:8081/health
  
  # Vision Service
  curl http://localhost:8082/health
  
  # NLP Service
  curl http://localhost:8083/health
  
  # Data Processor
  curl http://localhost:8084/health
  ```

### æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

- [ ] **LLMæ¨è«–ãƒ†ã‚¹ãƒˆ**
  ```bash
  curl -X POST http://localhost:8080/ai/llm/completion \
    -H "Content-Type: application/json" \
    -d '{"prompt":"Hello","max_tokens":10}'
  ```

- [ ] **ç”»åƒè§£æãƒ†ã‚¹ãƒˆ**
  ```bash
  curl -X POST http://localhost:8080/ai/vision/analyze \
    -H "Content-Type: application/json" \
    -d '{"image_base64":"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==","task":"analyze"}'
  ```

- [ ] **NLPå‡¦ç†ãƒ†ã‚¹ãƒˆ**
  ```bash
  curl -X POST http://localhost:8080/ai/nlp/process \
    -H "Content-Type: application/json" \
    -d '{"text":"This is great!","task":"sentiment"}'
  ```

- [ ] **ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ**
  ```bash
  curl -X POST http://localhost:8080/data/process \
    -H "Content-Type: application/json" \
    -d '{"operation":"analyze","data":{"records":[{"id":1,"value":100}]}}'
  ```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

- [ ] **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“è¨ˆæ¸¬**
  ```bash
  # è¤‡æ•°å›å®Ÿè¡Œã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’ç¢ºèª
  for i in {1..5}; do
    time curl -s http://localhost:8080/health > /dev/null
  done
  ```

- [ ] **åŒæ™‚æ¥ç¶šãƒ†ã‚¹ãƒˆ**
  ```bash
  # Apache Bench (ab) ã§ãƒ†ã‚¹ãƒˆ
  ab -n 100 -c 10 http://localhost:8080/health
  ```

- [ ] **ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç¢ºèª**
  ```bash
  # CPUãƒ»ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
  podman stats --no-stream
  
  # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
  podman system df
  ```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

#### 1. Podèµ·å‹•ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `./scripts/deploy.sh start` ã§ã‚¨ãƒ©ãƒ¼

**ç¢ºèªé …ç›®**:
```bash
# systemd statusç¢ºèª
systemctl --user status ai-semble.pod

# ãƒ­ã‚°ç¢ºèª
journalctl --user -u ai-semble.pod -f

# Quadletè¨­å®šç¢ºèª
ls -la ~/.config/containers/systemd/
```

**è§£æ±ºæ–¹æ³•**:
```bash
# systemdè¨­å®šãƒªãƒ­ãƒ¼ãƒ‰
systemctl --user daemon-reload

# æ‰‹å‹•Podä½œæˆãƒ†ã‚¹ãƒˆ
podman pod create --name test-pod
podman pod rm test-pod
```

#### 2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: ã‚µãƒ¼ãƒ“ã‚¹é–“é€šä¿¡ãŒã§ããªã„

**ç¢ºèªé …ç›®**:
```bash
# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ…‹ç¢ºèª
podman network ls
podman network inspect ai-semble

# ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ç¢ºèª
sudo firewall-cmd --list-all
```

**è§£æ±ºæ–¹æ³•**:
```bash
# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†ä½œæˆ
podman network rm ai-semble
podman network create ai-semble
```

#### 3. GPUèªè­˜ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: NVIDIA GPUãŒèªè­˜ã•ã‚Œãªã„

**ç¢ºèªé …ç›®**:
```bash
# GPUçŠ¶æ…‹ç¢ºèª
nvidia-smi

# CDIè¨­å®šç¢ºèª
ls -la /etc/cdi/

# crunè¨­å®šç¢ºèª
podman info | grep -i crun
```

**è§£æ±ºæ–¹æ³•**:
```bash
# CDIå†ç”Ÿæˆ
sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml

# crunè¨­å®š
sudo update-alternatives --set oci-runtime /usr/bin/crun
```

#### 4. ãƒœãƒªãƒ¥ãƒ¼ãƒ æ¨©é™ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: ãƒ‡ãƒ¼ã‚¿ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼

**ç¢ºèªé …ç›®**:
```bash
# ãƒœãƒªãƒ¥ãƒ¼ãƒ çŠ¶æ…‹ç¢ºèª
podman volume ls
podman volume inspect ai-semble-data

# SELinuxã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç¢ºèª
ls -laZ ~/.local/share/containers/storage/volumes/
```

**è§£æ±ºæ–¹æ³•**:
```bash
# SELinuxãƒ©ãƒ™ãƒ«ä¿®æ­£
restorecon -R ~/.local/share/containers/storage/volumes/

# ãƒœãƒªãƒ¥ãƒ¼ãƒ å†ä½œæˆ
podman volume rm ai-semble-data ai-semble-models
./scripts/setup.sh
```

## ğŸ“ˆ ç›£è¦–ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

### æ—¥å¸¸ç›£è¦–é …ç›®

```bash
# å®šæœŸå®Ÿè¡Œæ¨å¥¨ (cronç­‰ã§è‡ªå‹•åŒ–)

# ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
./scripts/deploy.sh status

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
./scripts/deploy.sh health

# ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç¢ºèª
podman stats --no-stream

# ãƒ­ã‚°ç¢ºèª
journalctl --user -u ai-semble.pod --since "1 hour ago"
```

### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

```bash
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
tar -czf ai-semble-config-$(date +%Y%m%d).tar.gz \
  ~/.config/containers/systemd/ \
  ~/ai-semble-p/

# ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
podman volume export ai-semble-data > ai-semble-data-$(date +%Y%m%d).tar
```

### æ›´æ–°æ‰‹é †

```bash
# æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¸ã®æ›´æ–°
git pull origin main
./scripts/deploy.sh stop
./scripts/setup.sh
./scripts/deploy.sh start
./scripts/deploy.sh health
```

## ğŸš¨ ç·Šæ€¥æ™‚å¯¾å¿œ

### ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢æ‰‹é †

```bash
# é€šå¸¸åœæ­¢
./scripts/deploy.sh stop

# å¼·åˆ¶åœæ­¢
podman pod kill ai-semble
podman pod rm ai-semble
```

### ãƒ‡ãƒ¼ã‚¿å¾©æ—§æ‰‹é †

```bash
# ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿å¾©å…ƒ
podman volume import ai-semble-data ai-semble-data-20241205.tar

# Podå†èµ·å‹•
./scripts/deploy.sh start
```

### é€£çµ¡å…ˆ

- **æŠ€è¡“ã‚µãƒãƒ¼ãƒˆ**: [ã‚µãƒãƒ¼ãƒˆçª“å£]
- **ç·Šæ€¥é€£çµ¡å…ˆ**: [ç·Šæ€¥é€£çµ¡å…ˆ]
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: https://github.com/ootakazuhiko/Ai-semble-p

---

ã“ã®ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦æ…é‡ã«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦é©åˆ‡ãªå¯¾å‡¦ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚